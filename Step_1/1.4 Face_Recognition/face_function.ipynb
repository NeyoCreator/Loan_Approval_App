{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\"\"\"Try to create a function for the face detection application\"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Try to create a function for the face detection application'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#import libraries\r\n",
    "import dlib\r\n",
    "import matplotlib.pyplot as plt \r\n",
    "import numpy as np\r\n",
    "import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def face_recognition(img1,img2):\r\n",
    "\r\n",
    "    same = 0\r\n",
    "\r\n",
    "    #1.set the object and model \r\n",
    "    detector = dlib.get_frontal_face_detector()\r\n",
    "    sp = dlib.shape_predictor(\"shape_predictor_5_face_landmarks.dat\")\r\n",
    "    model = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')\r\n",
    "\r\n",
    "    #2.apply face detection  using detector object \r\n",
    "    img1_detect = detector(img1,1)\r\n",
    "    img2_detect = detector(img2,1)\r\n",
    "\r\n",
    "    #3.get the image shapes \r\n",
    "    img1_shape = sp(img1,img1_detect[0])\r\n",
    "    img2_shape = sp(img2,img2_detect[0])\r\n",
    "\r\n",
    "    #4.align the images \r\n",
    "    img1_align = dlib.get_face_chip(img1, img1_shape)\r\n",
    "    img2_align = dlib.get_face_chip(img2, img2_shape)\r\n",
    "\r\n",
    "    #5.implement the model \r\n",
    "    img1_rep = model.compute_face_descriptor(img1_align)\r\n",
    "    img2_rep = model.compute_face_descriptor(img2_align)\r\n",
    "\r\n",
    "    #7.the representation of the images are dlib.vectors we need to convert them into numpy arrays\r\n",
    "    img1_rep = np.array(img1_rep)\r\n",
    "    img2_rep = np.array(img2_rep)\r\n",
    "\r\n",
    "    def find_distance(img_x1, img_x2):\r\n",
    "        euclidian_distance = img_x1 - img_x2\r\n",
    "        euclidian_distance = np.sum(np.multiply(euclidian_distance,euclidian_distance))\r\n",
    "        euclidian_distance = np.sqrt(euclidian_distance)\r\n",
    "        return euclidian_distance\r\n",
    "\r\n",
    "    distance = find_distance(img1_rep,img2_rep)\r\n",
    "\r\n",
    "    #8.threshold value \r\n",
    "    threshold = 0.6 \r\n",
    "\r\n",
    "    if distance  < threshold :\r\n",
    "        same = 1\r\n",
    "    else :\r\n",
    "        same = 0\r\n",
    "\r\n",
    "    #same is a binary value , if the images are the same we return 1 if not 0\r\n",
    "\r\n",
    "    return same"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "#load the image\r\n",
    "img_face = cv2.imread('face_img_0.png')\r\n",
    "img_id = cv2.imread('id_img_1.png')\r\n",
    "\r\n",
    "#impelment the function\r\n",
    "face_recognition(img_face,img_id)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "a65086c3c9f076f48bef7927f4f794e49f110bea0d8d4a0dbfc033a1f9d78305"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}